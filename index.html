<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <script src="https://docs.opencv.org/3.4.1/opencv.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>

  <script type="module">
    var videoElement ;
    var canvasElement;
    var canvasCtx;
    
    var canvasElement2 ;
    var canvasCtx2;
    
    var canvasElementCV ;
    var canvasCtxCV;
    
    var selfieSegmentation;
    var faceMesh ;
    var camera; 
    let initialized=false;
    var cx=0;
    var cy=0;
    var dx=0;
    var dy=0;
    var prevDx=0;
    var prevDy=0;
    var scale=1.38;

    window.onload = function() {
      videoElement = document.getElementsByClassName('input_video')[0];
      canvasElement = document.getElementById('output_canvas');
      canvasCtx = canvasElement.getContext('2d');
      canvasElement2 = document.getElementById('base_canvas');
      canvasCtx2= canvasElement2.getContext('2d');
      canvasElementCV = document.getElementById('cv_canvas');
      canvasCtxCV= canvasElementCV.getContext('2d');
      
      selfieSegmentation = new SelfieSegmentation({locateFile: (file) => {
        return `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`;
      }});
      
      selfieSegmentation.setOptions({
        modelSelection: 0,
      });
    
      selfieSegmentation.onResults(onResults);
      
      
      faceMesh = new FaceMesh({locateFile: (file) => {
        return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
      }});
      faceMesh.setOptions({
        maxNumFaces: 1,
        refineLandmarks: false,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
      });
      faceMesh.onResults(onResults2);
      
      camera = new Camera(videoElement, {
        onFrame: async () => {
          await faceMesh.send({image: videoElement});
          await selfieSegmentation.send({image: videoElement});
        },     
        width: 640,
        height: 360
      });
    camera.start();
    };
    function onResults2(results) {
      if (results.multiFaceLandmarks) {
        for (const landmarks of results.multiFaceLandmarks) {
          //console.log(landmarks[1]);
          var margin=(canvasElement2.width-canvasElement.width)/2;
          var halfWidth=canvasElement2.width/2;
          var halfHeight=canvasElement2.height/2;
         
          cx=landmarks[1].x*canvasElement2.width;
          
          var dx=cx-halfWidth;
          
          
          if(dx>margin){
            cx=margin+halfWidth;
          }
          else if(-dx>margin){
            cx=halfWidth-margin;
          }
          
          cy=landmarks[1].y*canvasElement2.height;
          var dy=cy-halfHeight;
          
          margin=(canvasElement2.height-canvasElement.height)/2;
          if(dy>margin){
            cy=margin+halfHeight;
          }
          else if(-dy>margin){
            cy=halfHeight-margin;
          }
        }
      }
    }
    function onResults(results) {
      //canvasのサイズを設定
      if(!initialized){
        initialized=true;
        //canvasのサイズは入力画像の2倍 (お好きなサイズでどうぞ)
        canvasElement.width=results.image.width*1.5;
        canvasElement.height=results.image.height*1.5;
        //入力画像と同じサイズのcanvasを用意
        canvasElement2.width=canvasElement.width*scale;
        canvasElement2.height=canvasElement.height*scale;
          
        canvasElementCV.width=results.image.width;
        canvasElementCV.height=results.image.height;
      }
      //拡大表示
      canvasCtxCV.drawImage(results.image, 0, 0, canvasElementCV.width, canvasElementCV.height);
      let src = cv.imread(canvasElementCV);
      let dst = new cv.Mat();
        
      let ksize = new cv.Size(9, 9);
      let anchor = new cv.Point(-1, -1);
      // You can try more different parameters
      cv.blur(src, dst, ksize, anchor, cv.BORDER_DEFAULT);
      
      cv.resize(dst,dst, new cv.Size(canvasElement2.width, canvasElement2.height), 0, 0, cv.INTER_AREA);
      
      const imgData = new ImageData(new Uint8ClampedArray(dst.data, dst.cols, dst.rows), dst.cols ,dst.rows);
      canvasCtx2.putImageData(imgData,0,0);
      
      src.delete(); dst.delete();
      
      dx=canvasElement.width/2-cx;
      dy=canvasElement.height/2-cy;
      dx=0.1*dx+0.9*prevDx;
      dy=0.1*dy+0.9*prevDy;
      prevDx=dx;
      prevDy=dy;
      
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
     
      
      canvasCtx.translate(dx,dy);
      
      canvasCtx.drawImage(results.segmentationMask, 0, 0,canvasElement2.width, canvasElement2.height);
      
       // Only overwrite existing pixels.
      canvasCtx.globalCompositeOperation = 'source-in';
      //ちょっと大きめに表示する
      canvasCtx.drawImage(results.image, 0, 0, canvasElement2.width, canvasElement2.height);
      
      //ちょっと大きめに表示する
      canvasCtx.globalCompositeOperation = 'destination-atop';
      canvasCtx.drawImage(canvasElement2, 0, 0, canvasElement2.width, canvasElement2.height);
      
      canvasCtx.restore();     
     
    }
</script>
  
</head>

<body>
  <div class="container">
    <video class="input_video" style="position:absolute; display:none;"></video>
    <canvas id="cv_canvas"  style="position:absolute;display:none;"></canvas>
    <canvas id="base_canvas"  style="position:absolute;display:none;"></canvas>
    <canvas id="output_canvas" style="position:absolute;"></canvas>
  </div>
</body>
</html>
